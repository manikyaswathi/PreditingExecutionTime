{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, math, copy\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "print(tf.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      predic      actual\n",
      "0  10.678091    4.539089\n",
      "1  71.194316  454.495120\n",
      "2  68.201857   94.412598\n",
      "3 -17.130789    0.375797\n",
      "4  98.632505   88.072707\n",
      "Mean Squared Error: 969.9600259448212\n",
      "Mean Absolute Error: 19.073892495207705\n"
     ]
    }
   ],
   "source": [
    "df_pca = pd.read_csv('gray_scott.csv')\n",
    "# print(df_pca.head())\n",
    "feature_cols_pcs = [str(i) for i in range(0,13)]\n",
    "label_pca='walltime'\n",
    "X_pca = df_pca[feature_cols_pcs] # Features\n",
    "y_pca = df_pca[label_pca] # Target variable\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y_pca, test_size=0.3, random_state=1) \n",
    "\n",
    "linear_regress_pca = LinearRegression()\n",
    "linear_regress_pca.fit(X_train_pca,y_train_pca)\n",
    "y_pred_pca = linear_regress_pca.predict(X_test_pca)\n",
    "\n",
    "res_val_pca = []\n",
    "for p, a in zip(y_pred_pca, y_test_pca):\n",
    "    res_val_pca.append([p, a])\n",
    "res_pca = pd.DataFrame(res_val_pca, columns=[\"predic\", \"actual\"])\n",
    "print(res_pca.head())\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test_pca, y_pred_pca))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test_pca, y_pred_pca))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "220/220 [==============================] - 1s 1ms/step - loss: 747.0108 - mse: 747.0108 - mae: 14.4663 - val_loss: 673.2760 - val_mse: 673.2760 - val_mae: 11.3174\n",
      "Epoch 2/300\n",
      "220/220 [==============================] - 0s 923us/step - loss: 370.6231 - mse: 370.6231 - mae: 9.4913 - val_loss: 398.9055 - val_mse: 398.9055 - val_mae: 9.8739\n",
      "Epoch 3/300\n",
      "220/220 [==============================] - 0s 884us/step - loss: 301.1236 - mse: 301.1236 - mae: 8.7020 - val_loss: 306.7479 - val_mse: 306.7479 - val_mae: 8.9957\n",
      "Epoch 4/300\n",
      "220/220 [==============================] - 0s 914us/step - loss: 232.1999 - mse: 232.1999 - mae: 8.0349 - val_loss: 264.7262 - val_mse: 264.7262 - val_mae: 9.2586\n",
      "Epoch 5/300\n",
      "220/220 [==============================] - 0s 897us/step - loss: 176.2305 - mse: 176.2305 - mae: 7.1949 - val_loss: 199.6958 - val_mse: 199.6958 - val_mae: 7.4286\n",
      "Epoch 6/300\n",
      "220/220 [==============================] - 0s 898us/step - loss: 168.0656 - mse: 168.0656 - mae: 6.9086 - val_loss: 223.6670 - val_mse: 223.6670 - val_mae: 7.5917\n",
      "Epoch 7/300\n",
      "220/220 [==============================] - 0s 893us/step - loss: 169.4091 - mse: 169.4091 - mae: 6.9641 - val_loss: 228.2905 - val_mse: 228.2905 - val_mae: 7.9346\n",
      "Epoch 8/300\n",
      "220/220 [==============================] - 0s 884us/step - loss: 165.7794 - mse: 165.7794 - mae: 6.7756 - val_loss: 247.9725 - val_mse: 247.9725 - val_mae: 7.5270\n",
      "Epoch 9/300\n",
      "220/220 [==============================] - 0s 877us/step - loss: 162.4539 - mse: 162.4539 - mae: 6.6630 - val_loss: 183.0658 - val_mse: 183.0658 - val_mae: 6.6462\n",
      "Epoch 10/300\n",
      "220/220 [==============================] - 0s 927us/step - loss: 151.4779 - mse: 151.4779 - mae: 6.5137 - val_loss: 189.8011 - val_mse: 189.8011 - val_mae: 7.0872\n",
      "Epoch 11/300\n",
      "220/220 [==============================] - 0s 989us/step - loss: 173.8629 - mse: 173.8629 - mae: 6.8434 - val_loss: 150.4959 - val_mse: 150.4958 - val_mae: 6.4466\n",
      "Epoch 12/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 140.1502 - mse: 140.1502 - mae: 6.1437 - val_loss: 199.5178 - val_mse: 199.5178 - val_mae: 7.5588\n",
      "Epoch 13/300\n",
      "220/220 [==============================] - 0s 945us/step - loss: 159.3938 - mse: 159.3938 - mae: 6.4989 - val_loss: 189.4897 - val_mse: 189.4897 - val_mae: 7.1697\n",
      "Epoch 14/300\n",
      "220/220 [==============================] - 0s 922us/step - loss: 133.7142 - mse: 133.7142 - mae: 6.0589 - val_loss: 167.0618 - val_mse: 167.0618 - val_mae: 7.0391\n",
      "Epoch 15/300\n",
      "220/220 [==============================] - 0s 910us/step - loss: 125.6227 - mse: 125.6227 - mae: 5.6375 - val_loss: 183.6191 - val_mse: 183.6190 - val_mae: 7.8935\n",
      "Epoch 16/300\n",
      "220/220 [==============================] - 0s 939us/step - loss: 134.6484 - mse: 134.6484 - mae: 6.0701 - val_loss: 154.8976 - val_mse: 154.8976 - val_mae: 6.4801\n",
      "Epoch 17/300\n",
      "220/220 [==============================] - 0s 962us/step - loss: 122.4371 - mse: 122.4371 - mae: 5.8019 - val_loss: 136.2587 - val_mse: 136.2587 - val_mae: 6.1766\n",
      "Epoch 18/300\n",
      "220/220 [==============================] - 0s 981us/step - loss: 123.7921 - mse: 123.7921 - mae: 5.7783 - val_loss: 141.2846 - val_mse: 141.2846 - val_mae: 6.5756\n",
      "Epoch 19/300\n",
      "220/220 [==============================] - 0s 985us/step - loss: 131.9659 - mse: 131.9659 - mae: 6.1286 - val_loss: 142.2719 - val_mse: 142.2719 - val_mae: 6.2326\n",
      "Epoch 20/300\n",
      "220/220 [==============================] - 0s 937us/step - loss: 131.1537 - mse: 131.1537 - mae: 6.0429 - val_loss: 139.5056 - val_mse: 139.5056 - val_mae: 6.3788\n",
      "Epoch 21/300\n",
      "220/220 [==============================] - 0s 904us/step - loss: 127.8920 - mse: 127.8920 - mae: 5.7984 - val_loss: 132.8515 - val_mse: 132.8515 - val_mae: 6.0360\n",
      "Epoch 22/300\n",
      "220/220 [==============================] - 0s 914us/step - loss: 117.4421 - mse: 117.4421 - mae: 5.6234 - val_loss: 132.2507 - val_mse: 132.2507 - val_mae: 6.2110\n",
      "Epoch 23/300\n",
      "220/220 [==============================] - 0s 958us/step - loss: 118.2256 - mse: 118.2256 - mae: 5.8227 - val_loss: 174.6132 - val_mse: 174.6132 - val_mae: 7.1813\n",
      "Epoch 24/300\n",
      "220/220 [==============================] - 0s 960us/step - loss: 135.5851 - mse: 135.5851 - mae: 6.0882 - val_loss: 166.5956 - val_mse: 166.5956 - val_mae: 6.9754\n",
      "Epoch 25/300\n",
      "220/220 [==============================] - 0s 944us/step - loss: 112.7521 - mse: 112.7521 - mae: 5.6636 - val_loss: 116.0836 - val_mse: 116.0836 - val_mae: 6.0474\n",
      "Epoch 26/300\n",
      "220/220 [==============================] - 0s 894us/step - loss: 109.4391 - mse: 109.4391 - mae: 5.5352 - val_loss: 151.9294 - val_mse: 151.9294 - val_mae: 6.8693\n",
      "Epoch 27/300\n",
      "220/220 [==============================] - 0s 895us/step - loss: 103.2682 - mse: 103.2682 - mae: 5.4075 - val_loss: 119.0581 - val_mse: 119.0581 - val_mae: 5.9538\n",
      "Epoch 28/300\n",
      "220/220 [==============================] - 0s 883us/step - loss: 114.9041 - mse: 114.9041 - mae: 5.5977 - val_loss: 119.3737 - val_mse: 119.3737 - val_mae: 5.7418\n",
      "Epoch 29/300\n",
      "220/220 [==============================] - 0s 873us/step - loss: 107.1468 - mse: 107.1468 - mae: 5.4199 - val_loss: 114.2712 - val_mse: 114.2712 - val_mae: 5.7641\n",
      "Epoch 30/300\n",
      "220/220 [==============================] - 0s 874us/step - loss: 107.3587 - mse: 107.3587 - mae: 5.5277 - val_loss: 133.3229 - val_mse: 133.3229 - val_mae: 6.2330\n",
      "Epoch 31/300\n",
      "220/220 [==============================] - 0s 874us/step - loss: 102.8661 - mse: 102.8661 - mae: 5.3407 - val_loss: 128.2131 - val_mse: 128.2131 - val_mae: 6.1728\n",
      "Epoch 32/300\n",
      "220/220 [==============================] - 0s 877us/step - loss: 136.0452 - mse: 136.0452 - mae: 6.0570 - val_loss: 108.8067 - val_mse: 108.8067 - val_mae: 5.8259\n",
      "Epoch 33/300\n",
      "220/220 [==============================] - 0s 877us/step - loss: 92.2964 - mse: 92.2964 - mae: 5.0172 - val_loss: 115.6984 - val_mse: 115.6984 - val_mae: 5.7913\n",
      "Epoch 34/300\n",
      "220/220 [==============================] - 0s 867us/step - loss: 97.1317 - mse: 97.1317 - mae: 5.3252 - val_loss: 118.7766 - val_mse: 118.7766 - val_mae: 6.0607\n",
      "Epoch 35/300\n",
      "220/220 [==============================] - 0s 875us/step - loss: 94.6668 - mse: 94.6668 - mae: 5.1495 - val_loss: 117.5294 - val_mse: 117.5294 - val_mae: 5.9926\n",
      "Epoch 36/300\n",
      "220/220 [==============================] - 0s 876us/step - loss: 88.6004 - mse: 88.6004 - mae: 5.0962 - val_loss: 114.6866 - val_mse: 114.6866 - val_mae: 6.3780\n",
      "Epoch 37/300\n",
      "220/220 [==============================] - 0s 927us/step - loss: 90.7109 - mse: 90.7109 - mae: 5.0889 - val_loss: 99.4303 - val_mse: 99.4303 - val_mae: 5.4512\n",
      "Epoch 38/300\n",
      "220/220 [==============================] - 0s 874us/step - loss: 95.6752 - mse: 95.6752 - mae: 5.1980 - val_loss: 172.3725 - val_mse: 172.3725 - val_mae: 6.9129\n",
      "Epoch 39/300\n",
      "220/220 [==============================] - 0s 917us/step - loss: 110.5681 - mse: 110.5681 - mae: 5.6222 - val_loss: 151.3453 - val_mse: 151.3453 - val_mae: 6.6818\n",
      "Epoch 40/300\n",
      "220/220 [==============================] - 0s 925us/step - loss: 89.5370 - mse: 89.5370 - mae: 5.0334 - val_loss: 116.6579 - val_mse: 116.6579 - val_mae: 5.7864\n",
      "Epoch 41/300\n",
      "220/220 [==============================] - 0s 878us/step - loss: 92.0387 - mse: 92.0387 - mae: 5.1028 - val_loss: 121.0928 - val_mse: 121.0928 - val_mae: 6.2971\n",
      "Epoch 42/300\n",
      "220/220 [==============================] - 0s 896us/step - loss: 87.7722 - mse: 87.7722 - mae: 4.9700 - val_loss: 118.2345 - val_mse: 118.2345 - val_mae: 5.8722\n",
      "Epoch 43/300\n",
      "220/220 [==============================] - 0s 937us/step - loss: 88.6377 - mse: 88.6377 - mae: 4.9825 - val_loss: 108.6361 - val_mse: 108.6361 - val_mae: 5.7190\n",
      "Epoch 44/300\n",
      "220/220 [==============================] - 0s 875us/step - loss: 98.2951 - mse: 98.2951 - mae: 5.2719 - val_loss: 127.4296 - val_mse: 127.4296 - val_mae: 5.8933\n",
      "Epoch 45/300\n",
      "220/220 [==============================] - 0s 904us/step - loss: 97.5939 - mse: 97.5939 - mae: 5.3015 - val_loss: 128.0761 - val_mse: 128.0761 - val_mae: 6.5058\n",
      "Epoch 46/300\n",
      "220/220 [==============================] - 0s 885us/step - loss: 83.5772 - mse: 83.5772 - mae: 4.8587 - val_loss: 101.9002 - val_mse: 101.9002 - val_mae: 5.2869\n",
      "Epoch 47/300\n",
      "220/220 [==============================] - 0s 873us/step - loss: 80.0019 - mse: 80.0019 - mae: 4.7695 - val_loss: 124.6039 - val_mse: 124.6039 - val_mae: 5.7637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "220/220 [==============================] - 0s 892us/step - loss: 89.5471 - mse: 89.5471 - mae: 5.0480 - val_loss: 112.0930 - val_mse: 112.0930 - val_mae: 5.7510\n",
      "Epoch 49/300\n",
      "220/220 [==============================] - 0s 894us/step - loss: 90.6312 - mse: 90.6312 - mae: 4.9984 - val_loss: 104.6789 - val_mse: 104.6789 - val_mae: 5.4943\n",
      "Epoch 50/300\n",
      "220/220 [==============================] - 0s 879us/step - loss: 81.4997 - mse: 81.4997 - mae: 4.7552 - val_loss: 106.4251 - val_mse: 106.4251 - val_mae: 5.4824\n",
      "Epoch 51/300\n",
      "220/220 [==============================] - 0s 874us/step - loss: 78.0369 - mse: 78.0369 - mae: 4.6202 - val_loss: 124.7375 - val_mse: 124.7375 - val_mae: 5.8598\n",
      "Epoch 52/300\n",
      "220/220 [==============================] - 0s 880us/step - loss: 78.1768 - mse: 78.1768 - mae: 4.5872 - val_loss: 105.4405 - val_mse: 105.4405 - val_mae: 5.5231\n",
      "Epoch 53/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 87.0588 - mse: 87.0588 - mae: 4.9530 - val_loss: 119.0535 - val_mse: 119.0535 - val_mae: 5.6947\n",
      "Epoch 54/300\n",
      "220/220 [==============================] - 0s 907us/step - loss: 77.9229 - mse: 77.9229 - mae: 4.6381 - val_loss: 103.2235 - val_mse: 103.2235 - val_mae: 5.3821\n",
      "Epoch 55/300\n",
      "220/220 [==============================] - 0s 891us/step - loss: 82.4698 - mse: 82.4698 - mae: 4.8011 - val_loss: 136.7160 - val_mse: 136.7160 - val_mae: 6.5923\n",
      "Epoch 56/300\n",
      "220/220 [==============================] - 0s 892us/step - loss: 98.0885 - mse: 98.0885 - mae: 5.1693 - val_loss: 152.1631 - val_mse: 152.1631 - val_mae: 6.0788\n",
      "Epoch 57/300\n",
      "220/220 [==============================] - 0s 875us/step - loss: 89.7158 - mse: 89.7158 - mae: 4.9805 - val_loss: 141.6554 - val_mse: 141.6554 - val_mae: 6.1118\n",
      "Epoch 58/300\n",
      "220/220 [==============================] - 0s 864us/step - loss: 101.4550 - mse: 101.4550 - mae: 5.1701 - val_loss: 114.3797 - val_mse: 114.3797 - val_mae: 5.6078\n",
      "Epoch 59/300\n",
      "220/220 [==============================] - 0s 870us/step - loss: 79.0095 - mse: 79.0095 - mae: 4.6346 - val_loss: 112.4612 - val_mse: 112.4612 - val_mae: 5.4170\n",
      "Epoch 60/300\n",
      "220/220 [==============================] - 0s 942us/step - loss: 76.8374 - mse: 76.8374 - mae: 4.5396 - val_loss: 101.2624 - val_mse: 101.2624 - val_mae: 5.5546\n",
      "Epoch 61/300\n",
      "220/220 [==============================] - 0s 913us/step - loss: 78.8378 - mse: 78.8378 - mae: 4.6527 - val_loss: 112.6957 - val_mse: 112.6957 - val_mae: 6.1016\n",
      "Epoch 62/300\n",
      "220/220 [==============================] - 0s 989us/step - loss: 79.3817 - mse: 79.3817 - mae: 4.7679 - val_loss: 129.3130 - val_mse: 129.3130 - val_mae: 6.9084\n",
      "Epoch 63/300\n",
      "220/220 [==============================] - 0s 978us/step - loss: 80.4929 - mse: 80.4929 - mae: 4.7814 - val_loss: 114.2839 - val_mse: 114.2839 - val_mae: 5.6361\n",
      "Epoch 64/300\n",
      "220/220 [==============================] - 0s 898us/step - loss: 76.8195 - mse: 76.8195 - mae: 4.6127 - val_loss: 103.5736 - val_mse: 103.5736 - val_mae: 5.4573\n",
      "Epoch 65/300\n",
      "220/220 [==============================] - 0s 975us/step - loss: 73.2061 - mse: 73.2061 - mae: 4.4289 - val_loss: 112.3332 - val_mse: 112.3332 - val_mae: 5.6940\n",
      "Epoch 66/300\n",
      "220/220 [==============================] - 0s 970us/step - loss: 76.1343 - mse: 76.1343 - mae: 4.5631 - val_loss: 108.2961 - val_mse: 108.2961 - val_mae: 5.5149\n",
      "Epoch 67/300\n",
      "220/220 [==============================] - 0s 984us/step - loss: 76.4334 - mse: 76.4334 - mae: 4.5708 - val_loss: 112.1669 - val_mse: 112.1669 - val_mae: 5.3150\n",
      "Epoch 68/300\n",
      "220/220 [==============================] - 0s 959us/step - loss: 77.9300 - mse: 77.9300 - mae: 4.6615 - val_loss: 117.7348 - val_mse: 117.7348 - val_mae: 5.8501\n",
      "Epoch 69/300\n",
      "220/220 [==============================] - 0s 956us/step - loss: 76.6319 - mse: 76.6319 - mae: 4.6115 - val_loss: 99.6366 - val_mse: 99.6366 - val_mae: 5.1700\n",
      "Epoch 70/300\n",
      "220/220 [==============================] - 0s 957us/step - loss: 72.7476 - mse: 72.7476 - mae: 4.5411 - val_loss: 106.4676 - val_mse: 106.4676 - val_mae: 5.6687\n",
      "Epoch 71/300\n",
      "220/220 [==============================] - 0s 983us/step - loss: 73.8607 - mse: 73.8607 - mae: 4.5239 - val_loss: 101.9612 - val_mse: 101.9612 - val_mae: 5.1845\n",
      "Epoch 72/300\n",
      "220/220 [==============================] - 0s 943us/step - loss: 72.6740 - mse: 72.6740 - mae: 4.3996 - val_loss: 103.9028 - val_mse: 103.9028 - val_mae: 5.3890\n",
      "Epoch 73/300\n",
      "220/220 [==============================] - 0s 920us/step - loss: 72.1012 - mse: 72.1012 - mae: 4.4904 - val_loss: 107.7247 - val_mse: 107.7247 - val_mae: 5.5091\n",
      "Epoch 74/300\n",
      "220/220 [==============================] - 0s 896us/step - loss: 74.8085 - mse: 74.8085 - mae: 4.6689 - val_loss: 121.1070 - val_mse: 121.1070 - val_mae: 5.5572\n",
      "Epoch 75/300\n",
      "220/220 [==============================] - 0s 939us/step - loss: 93.1561 - mse: 93.1561 - mae: 5.0168 - val_loss: 115.8928 - val_mse: 115.8928 - val_mae: 5.7403\n",
      "Epoch 76/300\n",
      "220/220 [==============================] - 0s 883us/step - loss: 77.1228 - mse: 77.1228 - mae: 4.5196 - val_loss: 125.2847 - val_mse: 125.2847 - val_mae: 5.8100\n",
      "Epoch 77/300\n",
      "220/220 [==============================] - 0s 873us/step - loss: 73.6660 - mse: 73.6660 - mae: 4.4209 - val_loss: 103.8586 - val_mse: 103.8586 - val_mae: 5.4486\n",
      "Epoch 78/300\n",
      "220/220 [==============================] - 0s 912us/step - loss: 69.3848 - mse: 69.3848 - mae: 4.2975 - val_loss: 101.2766 - val_mse: 101.2766 - val_mae: 5.1771\n",
      "Epoch 79/300\n",
      "220/220 [==============================] - 0s 916us/step - loss: 70.0317 - mse: 70.0317 - mae: 4.4024 - val_loss: 123.9447 - val_mse: 123.9447 - val_mae: 5.6305\n",
      "Epoch 80/300\n",
      "220/220 [==============================] - 0s 911us/step - loss: 71.9825 - mse: 71.9825 - mae: 4.4629 - val_loss: 101.3292 - val_mse: 101.3292 - val_mae: 5.1977\n",
      "Epoch 81/300\n",
      "220/220 [==============================] - 0s 922us/step - loss: 71.3271 - mse: 71.3271 - mae: 4.4124 - val_loss: 115.5414 - val_mse: 115.5414 - val_mae: 5.5104\n",
      "Epoch 82/300\n",
      "220/220 [==============================] - 0s 934us/step - loss: 73.2460 - mse: 73.2460 - mae: 4.4845 - val_loss: 107.3812 - val_mse: 107.3812 - val_mae: 5.3028\n",
      "Epoch 83/300\n",
      "220/220 [==============================] - 0s 893us/step - loss: 69.9626 - mse: 69.9626 - mae: 4.4063 - val_loss: 92.6927 - val_mse: 92.6927 - val_mae: 5.0327\n",
      "Epoch 84/300\n",
      "220/220 [==============================] - 0s 916us/step - loss: 81.0882 - mse: 81.0882 - mae: 4.6440 - val_loss: 119.1588 - val_mse: 119.1588 - val_mae: 5.5837\n",
      "Epoch 85/300\n",
      "220/220 [==============================] - 0s 924us/step - loss: 76.8850 - mse: 76.8850 - mae: 4.5342 - val_loss: 105.0566 - val_mse: 105.0566 - val_mae: 5.3570\n",
      "Epoch 86/300\n",
      "220/220 [==============================] - 0s 886us/step - loss: 75.7564 - mse: 75.7564 - mae: 4.5825 - val_loss: 107.3661 - val_mse: 107.3661 - val_mae: 5.4304\n",
      "Epoch 87/300\n",
      "220/220 [==============================] - 0s 886us/step - loss: 66.6672 - mse: 66.6672 - mae: 4.1955 - val_loss: 104.5024 - val_mse: 104.5024 - val_mae: 5.4476\n",
      "Epoch 88/300\n",
      "220/220 [==============================] - 0s 913us/step - loss: 67.8531 - mse: 67.8531 - mae: 4.1895 - val_loss: 101.5257 - val_mse: 101.5257 - val_mae: 5.0995\n",
      "Epoch 89/300\n",
      "220/220 [==============================] - 0s 891us/step - loss: 64.8616 - mse: 64.8616 - mae: 4.1383 - val_loss: 131.9144 - val_mse: 131.9144 - val_mae: 5.7521\n",
      "Epoch 90/300\n",
      "220/220 [==============================] - 0s 887us/step - loss: 71.2868 - mse: 71.2868 - mae: 4.4060 - val_loss: 119.9126 - val_mse: 119.9126 - val_mae: 5.5463\n",
      "Epoch 91/300\n",
      "220/220 [==============================] - 0s 914us/step - loss: 66.1626 - mse: 66.1626 - mae: 4.0850 - val_loss: 118.3173 - val_mse: 118.3173 - val_mae: 5.5856\n",
      "Epoch 92/300\n",
      "220/220 [==============================] - 0s 898us/step - loss: 75.6484 - mse: 75.6484 - mae: 4.5015 - val_loss: 124.1711 - val_mse: 124.1711 - val_mae: 6.0028\n",
      "Epoch 93/300\n",
      "220/220 [==============================] - 0s 896us/step - loss: 74.4451 - mse: 74.4451 - mae: 4.4637 - val_loss: 99.5078 - val_mse: 99.5078 - val_mae: 5.2770\n",
      "Epoch 94/300\n",
      "220/220 [==============================] - 0s 871us/step - loss: 71.3286 - mse: 71.3286 - mae: 4.3695 - val_loss: 102.4262 - val_mse: 102.4262 - val_mae: 5.1863\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 925us/step - loss: 70.2652 - mse: 70.2652 - mae: 4.2689 - val_loss: 104.8049 - val_mse: 104.8049 - val_mae: 5.4653\n",
      "Epoch 96/300\n",
      "220/220 [==============================] - 0s 902us/step - loss: 67.3229 - mse: 67.3229 - mae: 4.2120 - val_loss: 96.9790 - val_mse: 96.9790 - val_mae: 5.2541\n",
      "Epoch 97/300\n",
      "220/220 [==============================] - 0s 921us/step - loss: 71.1839 - mse: 71.1839 - mae: 4.3342 - val_loss: 101.0302 - val_mse: 101.0302 - val_mae: 5.3329\n",
      "Epoch 98/300\n",
      "220/220 [==============================] - 0s 934us/step - loss: 67.2629 - mse: 67.2629 - mae: 4.1972 - val_loss: 104.5108 - val_mse: 104.5108 - val_mae: 5.2929\n",
      "Epoch 99/300\n",
      "220/220 [==============================] - 0s 894us/step - loss: 64.2773 - mse: 64.2773 - mae: 4.0213 - val_loss: 111.4924 - val_mse: 111.4924 - val_mae: 5.8558\n",
      "Epoch 100/300\n",
      "220/220 [==============================] - 0s 900us/step - loss: 72.9757 - mse: 72.9757 - mae: 4.4047 - val_loss: 109.5961 - val_mse: 109.5961 - val_mae: 5.3100\n",
      "Epoch 101/300\n",
      "220/220 [==============================] - 0s 926us/step - loss: 64.7621 - mse: 64.7621 - mae: 4.1346 - val_loss: 101.0833 - val_mse: 101.0833 - val_mae: 5.4825\n",
      "Epoch 102/300\n",
      "220/220 [==============================] - 0s 932us/step - loss: 73.4279 - mse: 73.4279 - mae: 4.4331 - val_loss: 112.7561 - val_mse: 112.7561 - val_mae: 5.2451\n",
      "Epoch 103/300\n",
      "220/220 [==============================] - 0s 914us/step - loss: 67.6087 - mse: 67.6087 - mae: 4.2051 - val_loss: 112.1270 - val_mse: 112.1270 - val_mae: 5.5848\n",
      "Epoch 104/300\n",
      "220/220 [==============================] - 0s 912us/step - loss: 76.7333 - mse: 76.7333 - mae: 4.5890 - val_loss: 105.0726 - val_mse: 105.0726 - val_mae: 5.1430\n",
      "Epoch 105/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 64.8101 - mse: 64.8101 - mae: 4.0348 - val_loss: 98.3686 - val_mse: 98.3686 - val_mae: 5.0236\n",
      "Epoch 106/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 63.3354 - mse: 63.3354 - mae: 3.9686 - val_loss: 101.8482 - val_mse: 101.8482 - val_mae: 5.1254\n",
      "Epoch 107/300\n",
      "220/220 [==============================] - 0s 956us/step - loss: 67.9080 - mse: 67.9080 - mae: 4.2108 - val_loss: 109.9630 - val_mse: 109.9630 - val_mae: 5.4604\n",
      "Epoch 108/300\n",
      "220/220 [==============================] - 0s 917us/step - loss: 65.3973 - mse: 65.3973 - mae: 4.1690 - val_loss: 94.3315 - val_mse: 94.3315 - val_mae: 5.0731\n",
      "Epoch 109/300\n",
      "220/220 [==============================] - 0s 926us/step - loss: 64.3920 - mse: 64.3920 - mae: 3.9930 - val_loss: 117.8106 - val_mse: 117.8106 - val_mae: 5.5437\n",
      "Epoch 110/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 66.6247 - mse: 66.6247 - mae: 4.0495 - val_loss: 107.5073 - val_mse: 107.5073 - val_mae: 5.2695\n",
      "Epoch 111/300\n",
      "220/220 [==============================] - 0s 958us/step - loss: 66.9837 - mse: 66.9837 - mae: 4.1971 - val_loss: 103.9080 - val_mse: 103.9080 - val_mae: 5.1961\n",
      "Epoch 112/300\n",
      "220/220 [==============================] - 0s 938us/step - loss: 67.2158 - mse: 67.2158 - mae: 4.1708 - val_loss: 116.0577 - val_mse: 116.0577 - val_mae: 5.6665\n",
      "Epoch 113/300\n",
      "220/220 [==============================] - 0s 925us/step - loss: 70.6947 - mse: 70.6947 - mae: 4.2704 - val_loss: 158.0446 - val_mse: 158.0446 - val_mae: 6.6737\n",
      "Epoch 114/300\n",
      "220/220 [==============================] - 0s 938us/step - loss: 72.4761 - mse: 72.4761 - mae: 4.3269 - val_loss: 120.4907 - val_mse: 120.4907 - val_mae: 5.8067\n",
      "Epoch 115/300\n",
      "220/220 [==============================] - 0s 922us/step - loss: 72.3857 - mse: 72.3857 - mae: 4.3374 - val_loss: 106.6434 - val_mse: 106.6434 - val_mae: 5.3094\n",
      "Epoch 116/300\n",
      "220/220 [==============================] - 0s 947us/step - loss: 61.5678 - mse: 61.5678 - mae: 3.9581 - val_loss: 104.5640 - val_mse: 104.5640 - val_mae: 5.3213\n",
      "Epoch 117/300\n",
      "220/220 [==============================] - 0s 999us/step - loss: 59.8273 - mse: 59.8273 - mae: 3.8134 - val_loss: 100.2293 - val_mse: 100.2293 - val_mae: 4.9900\n",
      "Epoch 118/300\n",
      "220/220 [==============================] - 0s 956us/step - loss: 61.5322 - mse: 61.5322 - mae: 3.8130 - val_loss: 112.9013 - val_mse: 112.9013 - val_mae: 5.5513\n",
      "Epoch 119/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 60.7929 - mse: 60.7929 - mae: 3.8838 - val_loss: 113.1732 - val_mse: 113.1732 - val_mae: 5.3002\n",
      "Epoch 120/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 62.9854 - mse: 62.9854 - mae: 3.9194 - val_loss: 98.9212 - val_mse: 98.9212 - val_mae: 5.0576\n",
      "Epoch 121/300\n",
      "220/220 [==============================] - 0s 937us/step - loss: 60.8486 - mse: 60.8486 - mae: 3.9692 - val_loss: 122.7950 - val_mse: 122.7950 - val_mae: 5.6113\n",
      "Epoch 122/300\n",
      "220/220 [==============================] - 0s 886us/step - loss: 73.5166 - mse: 73.5166 - mae: 4.2246 - val_loss: 107.4531 - val_mse: 107.4531 - val_mae: 5.4054\n",
      "Epoch 123/300\n",
      "220/220 [==============================] - 0s 949us/step - loss: 64.7741 - mse: 64.7741 - mae: 4.0359 - val_loss: 105.2578 - val_mse: 105.2578 - val_mae: 5.2092\n",
      "Epoch 124/300\n",
      "220/220 [==============================] - 0s 915us/step - loss: 59.6845 - mse: 59.6845 - mae: 3.7768 - val_loss: 99.9329 - val_mse: 99.9329 - val_mae: 5.0155\n",
      "Epoch 125/300\n",
      "220/220 [==============================] - 0s 911us/step - loss: 62.9378 - mse: 62.9378 - mae: 3.9535 - val_loss: 99.0225 - val_mse: 99.0225 - val_mae: 5.2237\n",
      "Epoch 126/300\n",
      "220/220 [==============================] - 0s 928us/step - loss: 59.7709 - mse: 59.7709 - mae: 3.9191 - val_loss: 110.3510 - val_mse: 110.3510 - val_mae: 5.2527\n",
      "Epoch 127/300\n",
      "220/220 [==============================] - 0s 900us/step - loss: 61.2719 - mse: 61.2719 - mae: 3.8186 - val_loss: 131.7945 - val_mse: 131.7945 - val_mae: 5.8440\n",
      "Epoch 128/300\n",
      "220/220 [==============================] - 0s 924us/step - loss: 73.2553 - mse: 73.2553 - mae: 4.4801 - val_loss: 134.3869 - val_mse: 134.3869 - val_mae: 5.4179\n",
      "Epoch 129/300\n",
      "220/220 [==============================] - 0s 946us/step - loss: 74.0404 - mse: 74.0404 - mae: 4.3454 - val_loss: 97.3224 - val_mse: 97.3224 - val_mae: 5.1077\n",
      "Epoch 130/300\n",
      "220/220 [==============================] - 0s 943us/step - loss: 56.6107 - mse: 56.6107 - mae: 3.6849 - val_loss: 96.6297 - val_mse: 96.6297 - val_mae: 5.1019\n",
      "Epoch 131/300\n",
      "220/220 [==============================] - 0s 931us/step - loss: 62.6076 - mse: 62.6076 - mae: 3.8438 - val_loss: 130.9501 - val_mse: 130.9501 - val_mae: 5.5263\n",
      "Epoch 132/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 63.8514 - mse: 63.8514 - mae: 3.9721 - val_loss: 93.6025 - val_mse: 93.6025 - val_mae: 5.0228\n",
      "Epoch 133/300\n",
      "220/220 [==============================] - 0s 986us/step - loss: 59.7092 - mse: 59.7092 - mae: 3.7693 - val_loss: 108.5839 - val_mse: 108.5839 - val_mae: 5.3794\n",
      "Epoch 134/300\n",
      "220/220 [==============================] - 0s 911us/step - loss: 61.2134 - mse: 61.2134 - mae: 3.8335 - val_loss: 93.7335 - val_mse: 93.7335 - val_mae: 4.8410\n",
      "Epoch 135/300\n",
      "220/220 [==============================] - 0s 897us/step - loss: 59.5000 - mse: 59.5000 - mae: 3.8782 - val_loss: 99.8344 - val_mse: 99.8344 - val_mae: 5.3240\n",
      "Epoch 136/300\n",
      "220/220 [==============================] - 0s 924us/step - loss: 65.7704 - mse: 65.7704 - mae: 4.0579 - val_loss: 100.5923 - val_mse: 100.5923 - val_mae: 5.0648\n",
      "Epoch 137/300\n",
      "220/220 [==============================] - 0s 894us/step - loss: 59.4662 - mse: 59.4662 - mae: 3.8267 - val_loss: 98.1904 - val_mse: 98.1904 - val_mae: 5.0997\n",
      "Epoch 138/300\n",
      "220/220 [==============================] - 0s 885us/step - loss: 60.2609 - mse: 60.2609 - mae: 3.7910 - val_loss: 102.9787 - val_mse: 102.9787 - val_mae: 5.3551\n",
      "Epoch 139/300\n",
      "220/220 [==============================] - 0s 929us/step - loss: 61.2590 - mse: 61.2590 - mae: 3.9001 - val_loss: 95.5157 - val_mse: 95.5157 - val_mae: 5.0184\n",
      "Epoch 140/300\n",
      "220/220 [==============================] - 0s 877us/step - loss: 61.8380 - mse: 61.8380 - mae: 3.8980 - val_loss: 93.6460 - val_mse: 93.6460 - val_mae: 4.8735\n",
      "Epoch 141/300\n",
      "220/220 [==============================] - 0s 936us/step - loss: 65.0355 - mse: 65.0355 - mae: 4.0270 - val_loss: 107.2066 - val_mse: 107.2066 - val_mae: 5.6918\n",
      "Epoch 142/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 897us/step - loss: 67.7072 - mse: 67.7072 - mae: 4.0517 - val_loss: 103.4055 - val_mse: 103.4055 - val_mae: 5.1013\n",
      "Epoch 143/300\n",
      "220/220 [==============================] - 0s 900us/step - loss: 62.6785 - mse: 62.6785 - mae: 3.9747 - val_loss: 105.0707 - val_mse: 105.0707 - val_mae: 5.1948\n",
      "Epoch 144/300\n",
      "220/220 [==============================] - 0s 930us/step - loss: 58.3616 - mse: 58.3616 - mae: 3.7567 - val_loss: 92.1584 - val_mse: 92.1584 - val_mae: 4.8128\n",
      "Epoch 145/300\n",
      "220/220 [==============================] - 0s 928us/step - loss: 56.7128 - mse: 56.7128 - mae: 3.6822 - val_loss: 95.0008 - val_mse: 95.0009 - val_mae: 4.9145\n",
      "Epoch 146/300\n",
      "220/220 [==============================] - 0s 890us/step - loss: 58.3402 - mse: 58.3402 - mae: 3.7401 - val_loss: 98.4706 - val_mse: 98.4706 - val_mae: 4.9866\n",
      "Epoch 147/300\n",
      "220/220 [==============================] - 0s 889us/step - loss: 57.2746 - mse: 57.2746 - mae: 3.6985 - val_loss: 96.5644 - val_mse: 96.5644 - val_mae: 5.0922\n",
      "Epoch 148/300\n",
      "220/220 [==============================] - 0s 876us/step - loss: 53.7065 - mse: 53.7065 - mae: 3.5282 - val_loss: 86.6101 - val_mse: 86.6101 - val_mae: 4.6436\n",
      "Epoch 149/300\n",
      "220/220 [==============================] - 0s 912us/step - loss: 55.5705 - mse: 55.5705 - mae: 3.6578 - val_loss: 107.3671 - val_mse: 107.3671 - val_mae: 5.0252\n",
      "Epoch 150/300\n",
      "220/220 [==============================] - 0s 910us/step - loss: 59.2277 - mse: 59.2277 - mae: 3.7404 - val_loss: 93.8577 - val_mse: 93.8577 - val_mae: 4.7782\n",
      "Epoch 151/300\n",
      "220/220 [==============================] - 0s 893us/step - loss: 61.1854 - mse: 61.1854 - mae: 3.8959 - val_loss: 98.2507 - val_mse: 98.2507 - val_mae: 4.9341\n",
      "Epoch 152/300\n",
      "220/220 [==============================] - 0s 893us/step - loss: 60.6440 - mse: 60.6440 - mae: 3.8146 - val_loss: 105.1732 - val_mse: 105.1732 - val_mae: 5.1275\n",
      "Epoch 153/300\n",
      "220/220 [==============================] - 0s 915us/step - loss: 63.0551 - mse: 63.0551 - mae: 3.9479 - val_loss: 106.7440 - val_mse: 106.7440 - val_mae: 5.2575\n",
      "Epoch 154/300\n",
      "220/220 [==============================] - 0s 911us/step - loss: 55.5016 - mse: 55.5016 - mae: 3.6321 - val_loss: 98.2953 - val_mse: 98.2953 - val_mae: 4.9105\n",
      "Epoch 155/300\n",
      "220/220 [==============================] - 0s 903us/step - loss: 57.6551 - mse: 57.6551 - mae: 3.6777 - val_loss: 129.6599 - val_mse: 129.6599 - val_mae: 5.8667\n",
      "Epoch 156/300\n",
      "220/220 [==============================] - 0s 911us/step - loss: 58.1474 - mse: 58.1474 - mae: 3.7456 - val_loss: 125.6094 - val_mse: 125.6094 - val_mae: 5.5265\n",
      "Epoch 157/300\n",
      "220/220 [==============================] - 0s 887us/step - loss: 61.8721 - mse: 61.8721 - mae: 3.8618 - val_loss: 129.0081 - val_mse: 129.0081 - val_mae: 6.1093\n",
      "Epoch 158/300\n",
      "220/220 [==============================] - 0s 950us/step - loss: 59.6960 - mse: 59.6960 - mae: 3.7900 - val_loss: 100.2037 - val_mse: 100.2037 - val_mae: 4.9198\n",
      "Epoch 159/300\n",
      "220/220 [==============================] - 0s 926us/step - loss: 56.4109 - mse: 56.4109 - mae: 3.6124 - val_loss: 91.3995 - val_mse: 91.3995 - val_mae: 4.9321\n",
      "Epoch 160/300\n",
      "220/220 [==============================] - 0s 991us/step - loss: 58.2583 - mse: 58.2583 - mae: 3.6894 - val_loss: 85.7185 - val_mse: 85.7185 - val_mae: 4.6844\n",
      "Epoch 161/300\n",
      "220/220 [==============================] - 0s 978us/step - loss: 60.9343 - mse: 60.9343 - mae: 3.7278 - val_loss: 89.2800 - val_mse: 89.2800 - val_mae: 4.9721\n",
      "Epoch 162/300\n",
      "220/220 [==============================] - 0s 949us/step - loss: 57.0442 - mse: 57.0442 - mae: 3.6741 - val_loss: 99.3729 - val_mse: 99.3729 - val_mae: 5.1770\n",
      "Epoch 163/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 56.6444 - mse: 56.6444 - mae: 3.6185 - val_loss: 98.7217 - val_mse: 98.7217 - val_mae: 5.2127\n",
      "Epoch 164/300\n",
      "220/220 [==============================] - 0s 956us/step - loss: 60.7366 - mse: 60.7366 - mae: 3.7964 - val_loss: 106.7662 - val_mse: 106.7662 - val_mae: 5.0437\n",
      "Epoch 165/300\n",
      "220/220 [==============================] - 0s 925us/step - loss: 58.8572 - mse: 58.8572 - mae: 3.7040 - val_loss: 102.5656 - val_mse: 102.5656 - val_mae: 4.8613\n",
      "Epoch 166/300\n",
      "220/220 [==============================] - 0s 926us/step - loss: 62.4567 - mse: 62.4567 - mae: 3.8819 - val_loss: 105.2781 - val_mse: 105.2781 - val_mae: 5.1338\n",
      "Epoch 167/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 61.0490 - mse: 61.0490 - mae: 3.8585 - val_loss: 98.7721 - val_mse: 98.7721 - val_mae: 4.8622\n",
      "Epoch 168/300\n",
      "220/220 [==============================] - 0s 981us/step - loss: 56.7550 - mse: 56.7550 - mae: 3.6551 - val_loss: 93.8743 - val_mse: 93.8743 - val_mae: 4.8393\n",
      "Epoch 169/300\n",
      "220/220 [==============================] - 0s 965us/step - loss: 56.6824 - mse: 56.6824 - mae: 3.5929 - val_loss: 95.9477 - val_mse: 95.9477 - val_mae: 4.9732\n",
      "Epoch 170/300\n",
      "220/220 [==============================] - 0s 981us/step - loss: 54.6327 - mse: 54.6327 - mae: 3.5490 - val_loss: 90.8135 - val_mse: 90.8135 - val_mae: 4.6947\n",
      "Epoch 171/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 51.8972 - mse: 51.8972 - mae: 3.4047 - val_loss: 90.2500 - val_mse: 90.2500 - val_mae: 4.6687\n",
      "Epoch 172/300\n",
      "220/220 [==============================] - 0s 904us/step - loss: 53.5979 - mse: 53.5979 - mae: 3.4753 - val_loss: 91.0870 - val_mse: 91.0870 - val_mae: 4.7731\n",
      "Epoch 173/300\n",
      "220/220 [==============================] - 0s 900us/step - loss: 55.3070 - mse: 55.3070 - mae: 3.5963 - val_loss: 102.9352 - val_mse: 102.9352 - val_mae: 5.1268\n",
      "Epoch 174/300\n",
      "220/220 [==============================] - 0s 936us/step - loss: 62.3640 - mse: 62.3640 - mae: 3.8753 - val_loss: 97.5716 - val_mse: 97.5716 - val_mae: 5.1036\n",
      "Epoch 175/300\n",
      "220/220 [==============================] - 0s 936us/step - loss: 57.2828 - mse: 57.2828 - mae: 3.7067 - val_loss: 102.7928 - val_mse: 102.7928 - val_mae: 4.9881\n",
      "Epoch 176/300\n",
      "220/220 [==============================] - 0s 900us/step - loss: 59.7044 - mse: 59.7044 - mae: 3.7210 - val_loss: 109.8869 - val_mse: 109.8869 - val_mae: 5.1190\n",
      "Epoch 177/300\n",
      "220/220 [==============================] - 0s 895us/step - loss: 56.3656 - mse: 56.3656 - mae: 3.5816 - val_loss: 86.4991 - val_mse: 86.4991 - val_mae: 4.6930\n",
      "Epoch 178/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 52.7073 - mse: 52.7073 - mae: 3.4866 - val_loss: 91.8028 - val_mse: 91.8028 - val_mae: 4.7067\n",
      "Epoch 179/300\n",
      "220/220 [==============================] - 0s 916us/step - loss: 54.5653 - mse: 54.5653 - mae: 3.5605 - val_loss: 90.1764 - val_mse: 90.1764 - val_mae: 4.7657\n",
      "Epoch 180/300\n",
      "220/220 [==============================] - 0s 918us/step - loss: 58.1503 - mse: 58.1503 - mae: 3.6933 - val_loss: 104.6535 - val_mse: 104.6535 - val_mae: 5.2670\n",
      "Epoch 181/300\n",
      "220/220 [==============================] - 0s 938us/step - loss: 59.5786 - mse: 59.5786 - mae: 3.7718 - val_loss: 111.4813 - val_mse: 111.4813 - val_mae: 5.2368\n",
      "Epoch 182/300\n",
      "220/220 [==============================] - 0s 887us/step - loss: 63.4734 - mse: 63.4734 - mae: 3.8650 - val_loss: 83.9366 - val_mse: 83.9366 - val_mae: 4.6361\n",
      "Epoch 183/300\n",
      "220/220 [==============================] - 0s 931us/step - loss: 55.8270 - mse: 55.8270 - mae: 3.5955 - val_loss: 94.0339 - val_mse: 94.0339 - val_mae: 4.8759\n",
      "Epoch 184/300\n",
      "220/220 [==============================] - 0s 907us/step - loss: 58.2805 - mse: 58.2805 - mae: 3.6587 - val_loss: 99.7904 - val_mse: 99.7904 - val_mae: 5.2781\n",
      "Epoch 185/300\n",
      "220/220 [==============================] - 0s 926us/step - loss: 54.6087 - mse: 54.6087 - mae: 3.5612 - val_loss: 96.4330 - val_mse: 96.4330 - val_mae: 4.7419\n",
      "Epoch 186/300\n",
      "220/220 [==============================] - 0s 922us/step - loss: 53.0166 - mse: 53.0166 - mae: 3.4606 - val_loss: 85.5015 - val_mse: 85.5015 - val_mae: 4.5485\n",
      "Epoch 187/300\n",
      "220/220 [==============================] - 0s 919us/step - loss: 52.8539 - mse: 52.8539 - mae: 3.4065 - val_loss: 93.9781 - val_mse: 93.9781 - val_mae: 4.7073\n",
      "Epoch 188/300\n",
      "220/220 [==============================] - 0s 909us/step - loss: 57.6209 - mse: 57.6209 - mae: 3.6565 - val_loss: 99.2051 - val_mse: 99.2051 - val_mae: 4.8623\n",
      "Epoch 189/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 929us/step - loss: 55.7600 - mse: 55.7600 - mae: 3.5760 - val_loss: 99.6256 - val_mse: 99.6256 - val_mae: 4.8670\n",
      "Epoch 190/300\n",
      "220/220 [==============================] - 0s 917us/step - loss: 58.2657 - mse: 58.2657 - mae: 3.6544 - val_loss: 109.8471 - val_mse: 109.8471 - val_mae: 5.2064\n",
      "Epoch 191/300\n",
      "220/220 [==============================] - 0s 893us/step - loss: 62.2992 - mse: 62.2992 - mae: 3.8568 - val_loss: 90.4533 - val_mse: 90.4533 - val_mae: 4.6659\n",
      "Epoch 192/300\n",
      "220/220 [==============================] - 0s 946us/step - loss: 54.4172 - mse: 54.4172 - mae: 3.4753 - val_loss: 98.1044 - val_mse: 98.1044 - val_mae: 4.7309\n",
      "Epoch 193/300\n",
      "220/220 [==============================] - 0s 909us/step - loss: 49.9301 - mse: 49.9301 - mae: 3.2675 - val_loss: 115.8874 - val_mse: 115.8874 - val_mae: 4.9953\n",
      "Epoch 194/300\n",
      "220/220 [==============================] - 0s 909us/step - loss: 52.9531 - mse: 52.9531 - mae: 3.4461 - val_loss: 90.3804 - val_mse: 90.3804 - val_mae: 4.7231\n",
      "Epoch 195/300\n",
      "220/220 [==============================] - 0s 929us/step - loss: 60.3999 - mse: 60.3999 - mae: 3.8198 - val_loss: 102.9123 - val_mse: 102.9123 - val_mae: 5.1066\n",
      "Epoch 196/300\n",
      "220/220 [==============================] - 0s 922us/step - loss: 55.1910 - mse: 55.1910 - mae: 3.5243 - val_loss: 91.7284 - val_mse: 91.7284 - val_mae: 4.7440\n",
      "Epoch 197/300\n",
      "220/220 [==============================] - 0s 907us/step - loss: 54.6844 - mse: 54.6844 - mae: 3.4875 - val_loss: 98.3877 - val_mse: 98.3877 - val_mae: 5.4084\n",
      "Epoch 198/300\n",
      "220/220 [==============================] - 0s 964us/step - loss: 59.0414 - mse: 59.0414 - mae: 3.7549 - val_loss: 118.3159 - val_mse: 118.3159 - val_mae: 5.1114\n",
      "Epoch 199/300\n",
      "220/220 [==============================] - 0s 887us/step - loss: 57.7148 - mse: 57.7148 - mae: 3.6479 - val_loss: 92.5285 - val_mse: 92.5285 - val_mae: 4.8350\n",
      "Epoch 200/300\n",
      "220/220 [==============================] - 0s 894us/step - loss: 56.9750 - mse: 56.9750 - mae: 3.6793 - val_loss: 107.9302 - val_mse: 107.9302 - val_mae: 4.9932\n",
      "Epoch 201/300\n",
      "220/220 [==============================] - 0s 898us/step - loss: 56.2547 - mse: 56.2547 - mae: 3.6618 - val_loss: 87.4678 - val_mse: 87.4678 - val_mae: 4.6864\n",
      "Epoch 202/300\n",
      "220/220 [==============================] - 0s 901us/step - loss: 57.6017 - mse: 57.6017 - mae: 3.6310 - val_loss: 92.2694 - val_mse: 92.2694 - val_mae: 4.7243\n",
      "Epoch 203/300\n",
      "220/220 [==============================] - 0s 894us/step - loss: 57.7361 - mse: 57.7361 - mae: 3.6684 - val_loss: 94.9905 - val_mse: 94.9905 - val_mae: 4.8295\n",
      "Epoch 204/300\n",
      "220/220 [==============================] - 0s 899us/step - loss: 51.8285 - mse: 51.8285 - mae: 3.4122 - val_loss: 90.2532 - val_mse: 90.2532 - val_mae: 4.6788\n",
      "Epoch 205/300\n",
      "220/220 [==============================] - 0s 943us/step - loss: 54.0006 - mse: 54.0006 - mae: 3.4779 - val_loss: 110.5904 - val_mse: 110.5904 - val_mae: 5.0375\n",
      "Epoch 206/300\n",
      "220/220 [==============================] - 0s 901us/step - loss: 50.6440 - mse: 50.6440 - mae: 3.3666 - val_loss: 95.0861 - val_mse: 95.0861 - val_mae: 4.7187\n",
      "Epoch 207/300\n",
      "220/220 [==============================] - 0s 919us/step - loss: 50.6958 - mse: 50.6958 - mae: 3.3206 - val_loss: 99.1146 - val_mse: 99.1146 - val_mae: 4.9375\n",
      "Epoch 208/300\n",
      "220/220 [==============================] - 0s 909us/step - loss: 53.7995 - mse: 53.7995 - mae: 3.4553 - val_loss: 105.7940 - val_mse: 105.7940 - val_mae: 4.9899\n",
      "Epoch 209/300\n",
      "220/220 [==============================] - 0s 969us/step - loss: 57.0796 - mse: 57.0796 - mae: 3.6431 - val_loss: 103.5647 - val_mse: 103.5647 - val_mae: 5.0002\n",
      "Epoch 210/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 54.7845 - mse: 54.7845 - mae: 3.4723 - val_loss: 96.7819 - val_mse: 96.7819 - val_mae: 4.9751\n",
      "Epoch 211/300\n",
      "220/220 [==============================] - 0s 913us/step - loss: 53.9785 - mse: 53.9785 - mae: 3.4712 - val_loss: 90.6135 - val_mse: 90.6135 - val_mae: 4.6611\n",
      "Epoch 212/300\n",
      "220/220 [==============================] - 0s 948us/step - loss: 56.7976 - mse: 56.7976 - mae: 3.6059 - val_loss: 93.5042 - val_mse: 93.5042 - val_mae: 4.8905\n",
      "Epoch 213/300\n",
      "220/220 [==============================] - 0s 975us/step - loss: 55.1151 - mse: 55.1151 - mae: 3.5491 - val_loss: 96.9556 - val_mse: 96.9556 - val_mae: 4.9435\n",
      "Epoch 214/300\n",
      "220/220 [==============================] - 0s 956us/step - loss: 53.4234 - mse: 53.4234 - mae: 3.3594 - val_loss: 107.3548 - val_mse: 107.3548 - val_mae: 4.9894\n",
      "Epoch 215/300\n",
      "220/220 [==============================] - 0s 954us/step - loss: 53.2143 - mse: 53.2143 - mae: 3.4167 - val_loss: 99.8243 - val_mse: 99.8243 - val_mae: 4.8988\n",
      "Epoch 216/300\n",
      "220/220 [==============================] - 0s 942us/step - loss: 53.2364 - mse: 53.2364 - mae: 3.4493 - val_loss: 93.5813 - val_mse: 93.5813 - val_mae: 4.7532\n",
      "Epoch 217/300\n",
      "220/220 [==============================] - 0s 935us/step - loss: 54.0292 - mse: 54.0292 - mae: 3.4910 - val_loss: 93.0819 - val_mse: 93.0819 - val_mae: 4.6484\n",
      "Epoch 218/300\n",
      "220/220 [==============================] - 0s 971us/step - loss: 53.5939 - mse: 53.5939 - mae: 3.4540 - val_loss: 91.7449 - val_mse: 91.7449 - val_mae: 4.7235\n",
      "Epoch 219/300\n",
      "220/220 [==============================] - 0s 955us/step - loss: 53.1216 - mse: 53.1216 - mae: 3.4471 - val_loss: 108.9367 - val_mse: 108.9367 - val_mae: 5.0215\n",
      "Epoch 220/300\n",
      "220/220 [==============================] - 0s 968us/step - loss: 55.3882 - mse: 55.3882 - mae: 3.5070 - val_loss: 85.1068 - val_mse: 85.1068 - val_mae: 4.7529\n",
      "Epoch 221/300\n",
      "220/220 [==============================] - 0s 965us/step - loss: 54.0986 - mse: 54.0986 - mae: 3.4975 - val_loss: 91.3040 - val_mse: 91.3040 - val_mae: 4.7140\n",
      "Epoch 222/300\n",
      "220/220 [==============================] - 0s 893us/step - loss: 54.1702 - mse: 54.1702 - mae: 3.4807 - val_loss: 92.3586 - val_mse: 92.3586 - val_mae: 4.9008\n",
      "Epoch 223/300\n",
      "220/220 [==============================] - 0s 913us/step - loss: 55.0268 - mse: 55.0268 - mae: 3.5361 - val_loss: 121.8694 - val_mse: 121.8694 - val_mae: 5.2473\n",
      "Epoch 224/300\n",
      "220/220 [==============================] - 0s 942us/step - loss: 52.3212 - mse: 52.3212 - mae: 3.4476 - val_loss: 88.2719 - val_mse: 88.2719 - val_mae: 4.6874\n",
      "Epoch 225/300\n",
      "220/220 [==============================] - 0s 945us/step - loss: 52.8257 - mse: 52.8257 - mae: 3.4774 - val_loss: 87.1681 - val_mse: 87.1681 - val_mae: 4.7090\n",
      "Epoch 226/300\n",
      "220/220 [==============================] - 0s 898us/step - loss: 52.3519 - mse: 52.3519 - mae: 3.4126 - val_loss: 100.4069 - val_mse: 100.4069 - val_mae: 4.8554\n",
      "Epoch 227/300\n",
      "220/220 [==============================] - 0s 903us/step - loss: 53.4117 - mse: 53.4117 - mae: 3.4439 - val_loss: 101.7600 - val_mse: 101.7600 - val_mae: 5.0282\n",
      "Epoch 228/300\n",
      "220/220 [==============================] - 0s 893us/step - loss: 56.2283 - mse: 56.2283 - mae: 3.6083 - val_loss: 83.0365 - val_mse: 83.0365 - val_mae: 4.6154\n",
      "Epoch 229/300\n",
      "220/220 [==============================] - 0s 901us/step - loss: 53.8039 - mse: 53.8039 - mae: 3.4293 - val_loss: 99.6467 - val_mse: 99.6467 - val_mae: 4.7246\n",
      "Epoch 230/300\n",
      "220/220 [==============================] - 0s 922us/step - loss: 50.0337 - mse: 50.0337 - mae: 3.2851 - val_loss: 83.8015 - val_mse: 83.8015 - val_mae: 4.5117\n",
      "Epoch 231/300\n",
      "220/220 [==============================] - 0s 925us/step - loss: 51.8895 - mse: 51.8895 - mae: 3.3789 - val_loss: 107.5793 - val_mse: 107.5793 - val_mae: 5.0415\n",
      "Epoch 232/300\n",
      "220/220 [==============================] - 0s 921us/step - loss: 55.0406 - mse: 55.0406 - mae: 3.5328 - val_loss: 88.6444 - val_mse: 88.6444 - val_mae: 4.8387\n",
      "Epoch 233/300\n",
      "220/220 [==============================] - 0s 906us/step - loss: 54.6057 - mse: 54.6057 - mae: 3.4946 - val_loss: 92.2476 - val_mse: 92.2476 - val_mae: 4.9631\n",
      "Epoch 234/300\n",
      "220/220 [==============================] - 0s 927us/step - loss: 53.2478 - mse: 53.2478 - mae: 3.4419 - val_loss: 86.7167 - val_mse: 86.7167 - val_mae: 4.4868\n",
      "Epoch 235/300\n",
      "220/220 [==============================] - 0s 923us/step - loss: 50.3789 - mse: 50.3789 - mae: 3.3036 - val_loss: 89.8103 - val_mse: 89.8103 - val_mae: 4.5845\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 950us/step - loss: 52.7053 - mse: 52.7053 - mae: 3.3575 - val_loss: 87.7119 - val_mse: 87.7119 - val_mae: 4.7219\n",
      "Epoch 237/300\n",
      "220/220 [==============================] - 0s 915us/step - loss: 51.2057 - mse: 51.2057 - mae: 3.2866 - val_loss: 88.3715 - val_mse: 88.3715 - val_mae: 4.6268\n",
      "Epoch 238/300\n",
      "220/220 [==============================] - 0s 915us/step - loss: 48.6780 - mse: 48.6780 - mae: 3.2232 - val_loss: 92.3312 - val_mse: 92.3312 - val_mae: 4.6281\n",
      "Epoch 239/300\n",
      "220/220 [==============================] - 0s 901us/step - loss: 50.3799 - mse: 50.3800 - mae: 3.3329 - val_loss: 89.0295 - val_mse: 89.0295 - val_mae: 4.7961\n",
      "Epoch 240/300\n",
      "220/220 [==============================] - 0s 918us/step - loss: 53.3292 - mse: 53.3292 - mae: 3.4858 - val_loss: 96.1751 - val_mse: 96.1751 - val_mae: 4.7981\n",
      "Epoch 241/300\n",
      "220/220 [==============================] - 0s 905us/step - loss: 52.1390 - mse: 52.1390 - mae: 3.4430 - val_loss: 93.6930 - val_mse: 93.6929 - val_mae: 4.7276\n",
      "Epoch 242/300\n",
      "220/220 [==============================] - 0s 912us/step - loss: 56.1591 - mse: 56.1591 - mae: 3.6423 - val_loss: 110.9386 - val_mse: 110.9386 - val_mae: 4.9629\n",
      "Epoch 243/300\n",
      "220/220 [==============================] - 0s 910us/step - loss: 56.6137 - mse: 56.6137 - mae: 3.6353 - val_loss: 90.8795 - val_mse: 90.8795 - val_mae: 4.8830\n",
      "Epoch 244/300\n",
      "220/220 [==============================] - 0s 932us/step - loss: 50.4496 - mse: 50.4496 - mae: 3.3220 - val_loss: 83.8532 - val_mse: 83.8532 - val_mae: 4.5147\n",
      "Epoch 245/300\n",
      "220/220 [==============================] - 0s 920us/step - loss: 49.9566 - mse: 49.9566 - mae: 3.2217 - val_loss: 89.7247 - val_mse: 89.7247 - val_mae: 4.8072\n",
      "Epoch 246/300\n",
      "220/220 [==============================] - ETA: 0s - loss: 48.5846 - mse: 48.5846 - mae: 3.272 - 0s 910us/step - loss: 50.0379 - mse: 50.0379 - mae: 3.3010 - val_loss: 80.5293 - val_mse: 80.5293 - val_mae: 4.4494\n",
      "Epoch 247/300\n",
      "220/220 [==============================] - 0s 925us/step - loss: 48.9138 - mse: 48.9138 - mae: 3.1757 - val_loss: 81.3739 - val_mse: 81.3739 - val_mae: 4.4501\n",
      "Epoch 248/300\n",
      "220/220 [==============================] - 0s 928us/step - loss: 50.2547 - mse: 50.2547 - mae: 3.2703 - val_loss: 91.0189 - val_mse: 91.0189 - val_mae: 4.9455\n",
      "Epoch 249/300\n",
      "220/220 [==============================] - 0s 922us/step - loss: 57.9789 - mse: 57.9789 - mae: 3.7690 - val_loss: 88.2119 - val_mse: 88.2119 - val_mae: 4.7541\n",
      "Epoch 250/300\n",
      "220/220 [==============================] - 0s 892us/step - loss: 60.9601 - mse: 60.9601 - mae: 3.8500 - val_loss: 85.1532 - val_mse: 85.1532 - val_mae: 4.6344\n",
      "Epoch 251/300\n",
      "220/220 [==============================] - 0s 914us/step - loss: 54.0537 - mse: 54.0537 - mae: 3.5174 - val_loss: 89.0313 - val_mse: 89.0313 - val_mae: 4.6340\n",
      "Epoch 252/300\n",
      "220/220 [==============================] - 0s 909us/step - loss: 50.8687 - mse: 50.8687 - mae: 3.2755 - val_loss: 104.9001 - val_mse: 104.9001 - val_mae: 5.0357\n",
      "Epoch 253/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 48.6590 - mse: 48.6590 - mae: 3.1878 - val_loss: 92.3893 - val_mse: 92.3893 - val_mae: 4.8580\n",
      "Epoch 254/300\n",
      "220/220 [==============================] - 0s 918us/step - loss: 52.0141 - mse: 52.0141 - mae: 3.3538 - val_loss: 92.5070 - val_mse: 92.5070 - val_mae: 4.8650\n",
      "Epoch 255/300\n",
      "220/220 [==============================] - 0s 914us/step - loss: 55.2520 - mse: 55.2520 - mae: 3.5232 - val_loss: 86.2315 - val_mse: 86.2315 - val_mae: 4.9685\n",
      "Epoch 256/300\n",
      "220/220 [==============================] - 0s 906us/step - loss: 55.9299 - mse: 55.9299 - mae: 3.5961 - val_loss: 89.2583 - val_mse: 89.2583 - val_mae: 4.8750\n",
      "Epoch 257/300\n",
      "220/220 [==============================] - 0s 907us/step - loss: 50.9831 - mse: 50.9831 - mae: 3.3598 - val_loss: 85.1516 - val_mse: 85.1516 - val_mae: 4.6790\n",
      "Epoch 258/300\n",
      "220/220 [==============================] - 0s 914us/step - loss: 49.5451 - mse: 49.5451 - mae: 3.2523 - val_loss: 81.5364 - val_mse: 81.5364 - val_mae: 4.6558\n",
      "Epoch 259/300\n",
      "220/220 [==============================] - 0s 957us/step - loss: 58.8980 - mse: 58.8980 - mae: 3.7720 - val_loss: 89.3037 - val_mse: 89.3037 - val_mae: 4.5675\n",
      "Epoch 260/300\n",
      "220/220 [==============================] - 0s 974us/step - loss: 48.8504 - mse: 48.8504 - mae: 3.2030 - val_loss: 80.8016 - val_mse: 80.8016 - val_mae: 4.5114\n",
      "Epoch 261/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 51.7855 - mse: 51.7855 - mae: 3.3190 - val_loss: 86.4554 - val_mse: 86.4554 - val_mae: 4.7089\n",
      "Epoch 262/300\n",
      "220/220 [==============================] - 0s 986us/step - loss: 52.0962 - mse: 52.0962 - mae: 3.4082 - val_loss: 82.8381 - val_mse: 82.8381 - val_mae: 4.6478\n",
      "Epoch 263/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 47.9950 - mse: 47.9950 - mae: 3.2094 - val_loss: 97.0268 - val_mse: 97.0268 - val_mae: 5.3545\n",
      "Epoch 264/300\n",
      "220/220 [==============================] - 0s 960us/step - loss: 50.3268 - mse: 50.3268 - mae: 3.2988 - val_loss: 95.2231 - val_mse: 95.2230 - val_mae: 4.7536\n",
      "Epoch 265/300\n",
      "220/220 [==============================] - 0s 953us/step - loss: 50.6582 - mse: 50.6582 - mae: 3.2681 - val_loss: 88.8135 - val_mse: 88.8135 - val_mae: 4.5443\n",
      "Epoch 266/300\n",
      "220/220 [==============================] - 0s 976us/step - loss: 51.2578 - mse: 51.2578 - mae: 3.3098 - val_loss: 93.8683 - val_mse: 93.8683 - val_mae: 4.8339\n",
      "Epoch 267/300\n",
      "220/220 [==============================] - 0s 975us/step - loss: 54.3954 - mse: 54.3954 - mae: 3.4977 - val_loss: 104.1046 - val_mse: 104.1046 - val_mae: 5.0996\n",
      "Epoch 268/300\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 53.5054 - mse: 53.5054 - mae: 3.4929 - val_loss: 94.6402 - val_mse: 94.6402 - val_mae: 4.6861\n",
      "Epoch 269/300\n",
      "220/220 [==============================] - 0s 959us/step - loss: 50.3662 - mse: 50.3662 - mae: 3.3042 - val_loss: 93.3259 - val_mse: 93.3259 - val_mae: 4.9390\n",
      "Epoch 270/300\n",
      "220/220 [==============================] - 0s 858us/step - loss: 49.2686 - mse: 49.2686 - mae: 3.2588 - val_loss: 104.0869 - val_mse: 104.0869 - val_mae: 4.9217\n",
      "Epoch 271/300\n",
      "220/220 [==============================] - 0s 857us/step - loss: 49.4966 - mse: 49.4966 - mae: 3.3466 - val_loss: 89.7968 - val_mse: 89.7968 - val_mae: 4.6166\n",
      "Epoch 272/300\n",
      "220/220 [==============================] - 0s 844us/step - loss: 49.8435 - mse: 49.8435 - mae: 3.3078 - val_loss: 91.6836 - val_mse: 91.6836 - val_mae: 4.9510\n",
      "Epoch 273/300\n",
      "220/220 [==============================] - 0s 842us/step - loss: 54.3580 - mse: 54.3580 - mae: 3.6210 - val_loss: 81.0116 - val_mse: 81.0116 - val_mae: 4.5424\n",
      "Epoch 274/300\n",
      "220/220 [==============================] - 0s 843us/step - loss: 52.8695 - mse: 52.8695 - mae: 3.4177 - val_loss: 88.9902 - val_mse: 88.9902 - val_mae: 4.6917\n",
      "Epoch 275/300\n",
      "220/220 [==============================] - 0s 859us/step - loss: 52.3213 - mse: 52.3213 - mae: 3.3673 - val_loss: 97.2190 - val_mse: 97.2190 - val_mae: 4.7174\n",
      "Epoch 276/300\n",
      "220/220 [==============================] - 0s 837us/step - loss: 49.3760 - mse: 49.3760 - mae: 3.2358 - val_loss: 90.7031 - val_mse: 90.7031 - val_mae: 4.8600\n",
      "Epoch 277/300\n",
      "220/220 [==============================] - 0s 836us/step - loss: 51.3624 - mse: 51.3624 - mae: 3.3383 - val_loss: 98.7120 - val_mse: 98.7120 - val_mae: 4.8893\n",
      "Epoch 278/300\n",
      "220/220 [==============================] - 0s 848us/step - loss: 52.5877 - mse: 52.5877 - mae: 3.4366 - val_loss: 89.5954 - val_mse: 89.5954 - val_mae: 4.8877\n",
      "Epoch 279/300\n",
      "220/220 [==============================] - 0s 846us/step - loss: 49.6094 - mse: 49.6094 - mae: 3.2528 - val_loss: 109.1883 - val_mse: 109.1883 - val_mae: 4.9144\n",
      "Epoch 280/300\n",
      "220/220 [==============================] - 0s 845us/step - loss: 52.7431 - mse: 52.7431 - mae: 3.4217 - val_loss: 106.9335 - val_mse: 106.9335 - val_mae: 5.0708\n",
      "Epoch 281/300\n",
      "220/220 [==============================] - 0s 847us/step - loss: 51.7476 - mse: 51.7477 - mae: 3.4016 - val_loss: 137.8323 - val_mse: 137.8323 - val_mae: 5.8230\n",
      "Epoch 282/300\n",
      "220/220 [==============================] - 0s 854us/step - loss: 54.5287 - mse: 54.5287 - mae: 3.4884 - val_loss: 93.7019 - val_mse: 93.7019 - val_mae: 4.6213\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 863us/step - loss: 48.4265 - mse: 48.4265 - mae: 3.2303 - val_loss: 90.9260 - val_mse: 90.9260 - val_mae: 4.7301\n",
      "Epoch 284/300\n",
      "220/220 [==============================] - 0s 839us/step - loss: 48.5548 - mse: 48.5548 - mae: 3.2476 - val_loss: 89.2732 - val_mse: 89.2732 - val_mae: 4.5944\n",
      "Epoch 285/300\n",
      "220/220 [==============================] - 0s 841us/step - loss: 53.1443 - mse: 53.1443 - mae: 3.3355 - val_loss: 94.2415 - val_mse: 94.2415 - val_mae: 4.8851\n",
      "Epoch 286/300\n",
      "220/220 [==============================] - 0s 842us/step - loss: 51.1885 - mse: 51.1885 - mae: 3.3564 - val_loss: 95.0373 - val_mse: 95.0373 - val_mae: 4.8058\n",
      "Epoch 287/300\n",
      "220/220 [==============================] - 0s 854us/step - loss: 47.7923 - mse: 47.7923 - mae: 3.1576 - val_loss: 88.9161 - val_mse: 88.9161 - val_mae: 4.6047\n",
      "Epoch 288/300\n",
      "220/220 [==============================] - 0s 854us/step - loss: 48.4225 - mse: 48.4225 - mae: 3.1922 - val_loss: 95.2291 - val_mse: 95.2291 - val_mae: 4.9270\n",
      "Epoch 289/300\n",
      "220/220 [==============================] - 0s 839us/step - loss: 48.9025 - mse: 48.9025 - mae: 3.1601 - val_loss: 95.2229 - val_mse: 95.2229 - val_mae: 4.8204\n",
      "Epoch 290/300\n",
      "220/220 [==============================] - 0s 843us/step - loss: 49.1786 - mse: 49.1786 - mae: 3.2141 - val_loss: 88.7238 - val_mse: 88.7238 - val_mae: 4.7474\n",
      "Epoch 291/300\n",
      "220/220 [==============================] - 0s 852us/step - loss: 52.1858 - mse: 52.1858 - mae: 3.4027 - val_loss: 103.8991 - val_mse: 103.8991 - val_mae: 4.8305\n",
      "Epoch 292/300\n",
      "220/220 [==============================] - 0s 848us/step - loss: 51.0962 - mse: 51.0962 - mae: 3.3564 - val_loss: 93.4067 - val_mse: 93.4067 - val_mae: 4.6462\n",
      "Epoch 293/300\n",
      "220/220 [==============================] - 0s 844us/step - loss: 50.8862 - mse: 50.8862 - mae: 3.2921 - val_loss: 78.5125 - val_mse: 78.5125 - val_mae: 4.5065\n",
      "Epoch 294/300\n",
      "220/220 [==============================] - 0s 854us/step - loss: 49.2932 - mse: 49.2932 - mae: 3.2753 - val_loss: 79.2496 - val_mse: 79.2496 - val_mae: 4.4142\n",
      "Epoch 295/300\n",
      "220/220 [==============================] - 0s 851us/step - loss: 50.4491 - mse: 50.4491 - mae: 3.3684 - val_loss: 93.3581 - val_mse: 93.3581 - val_mae: 4.9228\n",
      "Epoch 296/300\n",
      "220/220 [==============================] - 0s 899us/step - loss: 51.4493 - mse: 51.4493 - mae: 3.4038 - val_loss: 91.1387 - val_mse: 91.1387 - val_mae: 4.8581\n",
      "Epoch 297/300\n",
      "220/220 [==============================] - 0s 903us/step - loss: 51.7899 - mse: 51.7899 - mae: 3.4692 - val_loss: 104.3732 - val_mse: 104.3732 - val_mae: 5.1309\n",
      "Epoch 298/300\n",
      "220/220 [==============================] - 0s 905us/step - loss: 54.4038 - mse: 54.4038 - mae: 3.5697 - val_loss: 86.3640 - val_mse: 86.3640 - val_mae: 4.6624\n",
      "Epoch 299/300\n",
      "220/220 [==============================] - 0s 897us/step - loss: 52.3783 - mse: 52.3783 - mae: 3.4349 - val_loss: 90.7828 - val_mse: 90.7828 - val_mae: 4.9110\n",
      "Epoch 300/300\n",
      "220/220 [==============================] - 0s 898us/step - loss: 47.4579 - mse: 47.4579 - mae: 3.2072 - val_loss: 98.2680 - val_mse: 98.2680 - val_mae: 4.8589\n"
     ]
    }
   ],
   "source": [
    "# X_train_pca, X_test_pca, y_train_pca, y_test_pca\n",
    "# NN Model with one dimention\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, input_dim=X_train_pca.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(4, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['mse', 'mae'])\n",
    "history = model.fit(X_train_pca, y_train_pca, epochs=300, validation_split=0.2, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 532us/step - loss: 61.5718 - mse: 61.5718 - mae: 3.5916\n",
      "118/118 [==============================] - 0s 557us/step - loss: 76.9931 - mse: 76.9931 - mae: 4.1673\n",
      "       predic      actual\n",
      "0    6.833249    4.539089\n",
      "1  396.818268  454.495120\n",
      "2   88.858261   94.412598\n",
      "3    0.912985    0.375797\n",
      "4   93.378998   88.072707\n",
      "Mean Squared Error: 76.99314245387222\n",
      "Mean Absolute Error: 4.167312001228738\n"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model.evaluate(X_train_pca, y_train_pca, batch_size=20)\n",
    "model.evaluate(X_test_pca, y_test_pca, batch_size=20)\n",
    "\n",
    "y_pred_pca_2 = model.predict(X_test_pca).flatten()\n",
    "testy_np = y_test_pca.to_numpy()\n",
    "res_val_pca_2 = []\n",
    "for p, a in zip(y_pred_pca_2, testy_np):\n",
    "    res_val_pca_2.append([p, a])\n",
    "res_pca_2 = pd.DataFrame(res_val_pca_2, columns=[\"predic\", \"actual\"])\n",
    "print(res_pca_2.head())\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test_pca, y_pred_pca_2))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test_pca, y_pred_pca_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predic      actual\n",
      "0    5.045056    4.539089\n",
      "1  387.939560  454.495120\n",
      "2  123.206608   94.412598\n",
      "3    0.375797    0.375797\n",
      "4   88.072707   88.072707\n",
      "Mean Squared Error: 428.2844207975549\n",
      "Mean Absolute Error: 5.510168407059013\n"
     ]
    }
   ],
   "source": [
    "# X_train_pca, X_test_pca, y_train_pca, y_test_pca\n",
    "\n",
    "# create a regressor object\n",
    "regressor = DecisionTreeRegressor(random_state = 0) \n",
    "  \n",
    "# fit the regressor with X and Y data\n",
    "regressor.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "y_pred_pca_3 = regressor.predict(X_test_pca)\n",
    "\n",
    "res_val_pca_3 = []\n",
    "for p, a in zip(y_pred_pca_3, y_test_pca):\n",
    "    res_val_pca_3.append([p, a])\n",
    "res_val_pca_3 = pd.DataFrame(res_val_pca_3, columns=[\"predic\", \"actual\"])\n",
    "print(res_val_pca_3.head())\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test_pca, y_pred_pca_3))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test_pca, y_pred_pca_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
